import requests
import json
from pathlib import Path
from typing import Optional, List, Dict
from config import Config
import re

class TTSService:
    def __init__(self):
        self.host = Config.TTS_HOST
        self.port = Config.TTS_PORT
        self.base_url = f"http://{self.host}:{self.port}"
    
    def check_connection(self) -> bool:
        """æ£€æŸ¥TTSæœåŠ¡è¿æ¥"""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def text_to_speech(self, text: str, output_filename: str, voice: str = "default", speed: float = 1.0) -> Optional[str]:
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            # ç¡®ä¿è¾“å‡ºè·¯å¾„å­˜åœ¨
            output_path = Config.AUDIO_DIR / f"{output_filename}.wav"
            
            # è°ƒç”¨TTS API
            response = requests.post(
                f"{self.base_url}/tts",
                json={
                    "text": text,
                    "voice": voice,
                    "speed": speed,
                    "format": "wav"
                },
                timeout=60
            )
            
            if response.status_code == 200:
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                return str(output_path)
            else:
                print(f"TTSæœåŠ¡é”™è¯¯: {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            print("TTSè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            print(f"TTSè½¬æ¢å¤±è´¥: {str(e)}")
            return None
    
    def text_to_speech_with_comfyui(self, text: str, output_filename: str, reference_audio: str = None) -> Optional[str]:
        """ä½¿ç”¨ComfyUIçš„TTSå·¥ä½œæµè¿›è¡Œæ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            from .comfyui_service import ComfyUIService
            
            comfyui = ComfyUIService()
            
            print(f"\n=== ComfyUI TTS ç”Ÿæˆå¼€å§‹ ===")
            print(f"åŸå§‹æ–‡æœ¬: {text[:100]}...")
            
            # é¢„å¤„ç†æ–‡æœ¬ï¼Œè¿‡æ»¤æ‰æ‹¬å·å†…çš„éŸ³æ•ˆè¯´æ˜
            cleaned_text = self._clean_audio_script(text)
            print(f"æ¸…ç†åæ–‡æœ¬: {cleaned_text[:100]}...")
            print(f"è¾“å‡ºæ–‡ä»¶å: {output_filename}")
            
            # å¤„ç†å‚è€ƒéŸ³é¢‘
            speaker_filename = None
            if reference_audio:
                print(f"å‚è€ƒéŸ³é¢‘è·¯å¾„: {reference_audio}")
                speaker_filename = self._prepare_reference_audio(reference_audio)
                if not speaker_filename:
                    print(f"âš ï¸ å‚è€ƒéŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤éŸ³é¢‘")
                    return None  # å¦‚æœå‚è€ƒéŸ³é¢‘å¤±è´¥ï¼Œç›´æ¥è¿”å›å¤±è´¥
                else:
                    print(f"âœ… å‚è€ƒéŸ³é¢‘å·²å‡†å¤‡: {speaker_filename}")
            else:
                print(f"âš ï¸ æœªæä¾›å‚è€ƒéŸ³é¢‘")
                return None  # å¼ºåˆ¶è¦æ±‚å‚è€ƒéŸ³é¢‘
            
            # åŠ è½½TTSå·¥ä½œæµ
            workflow = comfyui.load_workflow(Config.TTS_WORKFLOW)
            
            # æ›´æ–°å·¥ä½œæµä¸­çš„æ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘
            workflow = self._update_tts_workflow(workflow, cleaned_text, speaker_filename)
            
            # æ‰§è¡Œå·¥ä½œæµ
            print(f"æ­£åœ¨æ‰§è¡ŒTTSå·¥ä½œæµ...")
            audio_path = comfyui._execute_workflow(workflow, f"audio_{output_filename}")
            
            if audio_path:
                print(f"âœ… ComfyUIè¿”å›çš„éŸ³é¢‘è·¯å¾„: {audio_path}")
                
                # éªŒè¯è¿”å›çš„æ–‡ä»¶ç¡®å®æ˜¯æ–°ç”Ÿæˆçš„ï¼Œè€Œä¸æ˜¯å‚è€ƒéŸ³é¢‘
                if self._validate_generated_audio(audio_path, reference_audio, cleaned_text):
                    # ç§»åŠ¨åˆ°éŸ³é¢‘ç›®å½•
                    final_path = Config.AUDIO_DIR / f"{output_filename}.wav"
                    Config.AUDIO_DIR.mkdir(parents=True, exist_ok=True)
                    
                    try:
                        import shutil
                        shutil.move(audio_path, final_path)
                        print(f"âœ… éŸ³é¢‘æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {final_path}")
                        print(f"=== ComfyUI TTS ç”Ÿæˆå®Œæˆ ===\n")
                        return str(final_path)
                    except Exception as e:
                        print(f"âš ï¸ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
                        # å¦‚æœç§»åŠ¨å¤±è´¥ï¼Œå°è¯•å¤åˆ¶
                        try:
                            import shutil
                            shutil.copy2(audio_path, final_path)
                            print(f"âœ… éŸ³é¢‘æ–‡ä»¶å·²å¤åˆ¶åˆ°: {final_path}")
                            return str(final_path)
                        except Exception as e2:
                            print(f"âŒ å¤åˆ¶æ–‡ä»¶ä¹Ÿå¤±è´¥: {e2}")
                            # æœ€åç›´æ¥è¿”å›åŸè·¯å¾„
                            return audio_path
                else:
                    print(f"âŒ éªŒè¯å¤±è´¥ï¼šç”Ÿæˆçš„éŸ³é¢‘å¯èƒ½ä¸å‚è€ƒéŸ³é¢‘ç›¸åŒ")
                    return None
            else:
                print(f"âŒ ComfyUIæ‰§è¡Œå¤±è´¥ï¼Œæœªè¿”å›éŸ³é¢‘æ–‡ä»¶")
            
            return None
            
        except Exception as e:
            print(f"âŒ ComfyUI TTSè½¬æ¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥é”™è¯¯
            if "WinError 10061" in str(e) or "Failed to establish a new connection" in str(e):
                print("ğŸš¨ ComfyUIæœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ComfyUIæ˜¯å¦æ­£å¸¸è¿è¡Œ")
            return None
    
    def _clean_audio_script(self, text: str) -> str:
        """æ¸…ç†éŸ³é¢‘è„šæœ¬ï¼Œè¿‡æ»¤æ‰æ‹¬å·å†…çš„éŸ³æ•ˆè¯´æ˜"""
        import re
        
        # ç§»é™¤å„ç§æ‹¬å·å†…çš„å†…å®¹
        patterns = [
            r'ï¼ˆ[^ï¼‰]*ï¼‰',  # ä¸­æ–‡æ‹¬å·ï¼ˆï¼‰
            r'\([^)]*\)',        # è‹±æ–‡æ‹¬å·()
            r'ã€[^ã€‘]*ã€‘',  # ä¸­æ–‡æ–¹æ‹¬å·ã€ã€‘
            r'\[[^\]]*\]',       # è‹±æ–‡æ–¹æ‹¬å·[]
            r'ã€Š[^ã€‹]*ã€‹',  # ä¹¦åå·ã€Šã€‹
            r'â€œ[^â€]*â€',  # åŒå¼•å·â€œâ€
        ]
        
        cleaned_text = text
        for pattern in patterns:
            cleaned_text = re.sub(pattern, '', cleaned_text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
        cleaned_text = cleaned_text.strip()
        
        return cleaned_text if cleaned_text.strip() else text

    def generate_subtitles(self, text: str, output_filename: str, 
                          audio_duration: Optional[float] = None,
                          words_per_second: float = 2.5) -> Optional[str]:
        """ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆSRTæ ¼å¼ï¼‰"""
        try:
            # æ¸…ç†æ–‡æœ¬ï¼Œè¿‡æ»¤æ‰æ‹¬å·å†…çš„éŸ³æ•ˆè¯´æ˜
            cleaned_text = self._clean_audio_script(text)
            
            # å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­
            sentences = self._split_text_into_sentences(cleaned_text)
            
            # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ—¶é•¿ï¼Œæ ¹æ®æ–‡å­—æ•°é‡ä¼°ç®—
            if audio_duration is None:
                total_words = len(cleaned_text.split())
                audio_duration = total_words / words_per_second
            
            # è®¡ç®—æ¯ä¸ªå¥å­çš„æ—¶é•¿
            sentence_durations = self._calculate_sentence_durations(sentences, audio_duration)
            
            # ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
            subtitle_path = Config.AUDIO_DIR / f"{output_filename}.srt"
            
            with open(subtitle_path, 'w', encoding='utf-8') as f:
                current_time = 0.0
                
                for i, (sentence, duration) in enumerate(zip(sentences, sentence_durations), 1):
                    start_time = current_time
                    end_time = current_time + duration
                    
                    # SRTæ—¶é—´æ ¼å¼ï¼šHH:MM:SS,mmm
                    start_srt = self._seconds_to_srt_time(start_time)
                    end_srt = self._seconds_to_srt_time(end_time)
                    
                    # å†™å…¥å­—å¹•æ¡ç›®
                    f.write(f"{i}\n")
                    f.write(f"{start_srt} --> {end_srt}\n")
                    f.write(f"{sentence.strip()}\n\n")
                    
                    current_time = end_time
            
            return str(subtitle_path)
            
        except Exception as e:
            print(f"ç”Ÿæˆå­—å¹•æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def _validate_generated_audio(self, generated_path: str, reference_path: str, text: str) -> bool:
        """éªŒè¯ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æ­£ç¡®"""
        try:
            from pathlib import Path
            import time
            
            generated_file = Path(generated_path)
            reference_file = Path(reference_path) if reference_path else None
            
            print(f"\n=== éªŒè¯ç”Ÿæˆçš„éŸ³é¢‘ ===")
            print(f"ç”Ÿæˆæ–‡ä»¶: {generated_file}")
            print(f"å‚è€ƒæ–‡ä»¶: {reference_file}")
            
            # æ£€æŸ¥ç”Ÿæˆæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not generated_file.exists():
                print(f"âŒ ç”Ÿæˆæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            generated_size = generated_file.stat().st_size
            print(f"ç”Ÿæˆæ–‡ä»¶å¤§å°: {generated_size/1024/1024:.2f}MB")
            
            if generated_size < 1024:  # å°äº1KB
                print(f"âŒ ç”Ÿæˆæ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ—¶é—´
            current_time = time.time()
            file_mtime = generated_file.stat().st_mtime
            age_seconds = current_time - file_mtime
            
            print(f"æ–‡ä»¶å¹´é¾„: {age_seconds:.1f}ç§’")
            
            if age_seconds > 300:  # 5åˆ†é’Ÿå‰çš„æ–‡ä»¶
                print(f"âš ï¸ æ–‡ä»¶å¤ªæ—§ï¼Œå¯èƒ½ä¸æ˜¯åˆšç”Ÿæˆçš„")
                # ä¸ç›´æ¥å¤±è´¥ï¼Œä½†ç»™å‡ºè­¦å‘Š
            
            # å¦‚æœæœ‰å‚è€ƒéŸ³é¢‘ï¼Œæ£€æŸ¥æ˜¯å¦ç›¸åŒ
            if reference_file and reference_file.exists():
                reference_size = reference_file.stat().st_size
                print(f"å‚è€ƒæ–‡ä»¶å¤§å°: {reference_size/1024/1024:.2f}MB")
                
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦ç›¸åŒ
                if str(generated_file.resolve()) == str(reference_file.resolve()):
                    print(f"âŒ ç”Ÿæˆæ–‡ä»¶ä¸å‚è€ƒæ–‡ä»¶è·¯å¾„ç›¸åŒ")
                    return False
                
                # æ£€æŸ¥å¤§å°æ˜¯å¦ç›¸åŒï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„é˜ˆå€¼ï¼‰
                size_diff = abs(generated_size - reference_size)
                similarity_threshold = max(1024, min(generated_size, reference_size) * 0.1)  # 1KBæˆ–1ï¼…ä¸­çš„è¾ƒå¤§å€¼
                
                if size_diff < similarity_threshold:
                    print(f"âš ï¸ ç”Ÿæˆæ–‡ä»¶ä¸å‚è€ƒæ–‡ä»¶å¤§å°ç›¸ä¼¼ï¼ˆç›¸å·®{size_diff}å­—èŠ‚ï¼Œé˜ˆå€¼{similarity_threshold}ï¼‰")
                    # è¿™é‡Œä¸ç›´æ¥å¤±è´¥ï¼Œå› ä¸ºæœ‰å¯èƒ½æ­£å¥½ç”Ÿæˆçš„æ–‡ä»¶å¤§å°ç›¸ä¼¼
                
                print(f"âœ… æ–‡ä»¶å¤§å°å·®å¼‚: {size_diff/1024:.1f}KB")
            
            # åŸºäºæ–‡æœ¬é•¿åº¦ä¼°ç®—æœŸæœ›çš„æ–‡ä»¶å¤§å°
            text_length = len(text)
            estimated_duration = text_length / 2.5  # ä¼°è®¡æ¯ç§’2.5ä¸ªå­—ç¬¦
            estimated_size = estimated_duration * 16000 * 2  # 16kHz, 16bit
            
            print(f"ä¼°è®¡æ—¶é•¿: {estimated_duration:.1f}ç§’")
            print(f"ä¼°è®¡å¤§å°: {estimated_size/1024/1024:.2f}MB")
            
            # å¦‚æœç”Ÿæˆæ–‡ä»¶æ˜æ˜¾å°äºé¢„æœŸï¼Œå¯èƒ½æœ‰é—®é¢˜
            if generated_size < estimated_size * 0.1:  # å°äºé¢„æœŸçš„10%
                print(f"âš ï¸ ç”Ÿæˆæ–‡ä»¶æ˜æ˜¾å°äºé¢„æœŸå¤§å°")
            
            print(f"âœ… éŸ³é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡")
            print(f"=== éªŒè¯å®Œæˆ ===\n")
            return True
            
        except Exception as e:
            print(f"âŒ éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return True  # éªŒè¯å¤±è´¥æ—¶é»˜è®¤é€šè¿‡
    
    def _update_tts_workflow(self, workflow: dict, text: str, speaker_filename: str = None) -> dict:
        """æ›´æ–°TTSå·¥ä½œæµä¸­çš„æ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘"""
        print(f"æ­£åœ¨æ›´æ–°TTSå·¥ä½œæµ...")
        print(f"è¾“å…¥æ–‡æœ¬: {text[:50]}...")
        if speaker_filename:
            print(f"å‚è€ƒéŸ³é¢‘: {speaker_filename}")
        
        updated_nodes = []
        
        for node_id, node_data in workflow.items():
            if isinstance(node_data, dict):
                # æŸ¥æ‰¾æ–‡æœ¬è¾“å…¥èŠ‚ç‚¹
                if node_data.get("class_type") in ["MultiLinePromptIndex", "TextInput", "TTSTextInput", "PromptNode"]:
                    if "inputs" in node_data:
                        # æŸ¥æ‰¾æ–‡æœ¬ç›¸å…³çš„å­—æ®µ
                        for key in node_data["inputs"]:
                            if "text" in key.lower() or "prompt" in key.lower() or "multi_line" in key.lower():
                                node_data["inputs"][key] = text
                                updated_nodes.append(f"Node {node_id}: {key} -> {text[:30]}...")
                                print(f"æ›´æ–°èŠ‚ç‚¹ {node_id} ({key}): {text[:30]}...")
                
                # æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘èŠ‚ç‚¹
                elif node_data.get("class_type") in ["IndexSpeakersPreview"] and speaker_filename:
                    if "inputs" in node_data:
                        # æŸ¥æ‰¾éŸ³é¢‘ç›¸å…³çš„å­—æ®µ
                        for key in node_data["inputs"]:
                            if "speaker" in key.lower() or "audio" in key.lower():
                                node_data["inputs"][key] = speaker_filename
                                updated_nodes.append(f"Node {node_id}: {key} -> {speaker_filename}")
                                print(f"æ›´æ–°èŠ‚ç‚¹ {node_id} ({key}): {speaker_filename}")
                
                # æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ–‡æœ¬å­—æ®µ
                elif "inputs" in node_data:
                    for key, value in node_data["inputs"].items():
                        if "text" in key.lower() and isinstance(value, str):
                            node_data["inputs"][key] = text
                            updated_nodes.append(f"Node {node_id}: {key} -> {text[:30]}...")
                            print(f"æ›´æ–°èŠ‚ç‚¹ {node_id} ({key}): {text[:30]}...")
        
        print(f"TTSå·¥ä½œæµæ›´æ–°å®Œæˆï¼Œå…±æ›´æ–°äº† {len(updated_nodes)} ä¸ªèŠ‚ç‚¹:")
        for update in updated_nodes:
            print(f"  - {update}")
        
        return workflow
    
    def _prepare_reference_audio(self, reference_audio_path: str) -> Optional[str]:
        """å‡†å¤‡å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼Œå¤åˆ¶åˆ°ComfyUIçš„speakersç›®å½•"""
        try:
            import shutil
            from pathlib import Path
            
            source_path = Path(reference_audio_path)
            if not source_path.exists():
                print(f"âŒ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {reference_audio_path}")
                return None
            
            print(f"ğŸ§ å‡†å¤‡å‚è€ƒéŸ³é¢‘: {source_path}")
            
            # ComfyUIçš„speakersç›®å½•è·¯å¾„
            comfyui_speakers_dirs = [
                Path("F:/ComfyUI_windows_portable/ComfyUI/models/TTS/speakers"),
                Path("./ComfyUI/models/TTS/speakers"),
                Path("../ComfyUI/models/TTS/speakers"),
                Path("C:/ComfyUI/models/TTS/speakers"),
                Path("D:/ComfyUI/models/TTS/speakers")
            ]
            
            speakers_dir = None
            for dir_path in comfyui_speakers_dirs:
                if dir_path.parent.parent.parent.exists():  # æ£€æŸ¥ComfyUIç›®å½•æ˜¯å¦å­˜åœ¨
                    speakers_dir = dir_path
                    break
            
            if not speakers_dir:
                print(f"âš ï¸ æ‰¾ä¸åˆ°ComfyUIçš„speakersç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
                speakers_dir = Path("F:/ComfyUI_windows_portable/ComfyUI/models/TTS/speakers")
            
            # åˆ›å»ºç›®å½•
            speakers_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… speakersç›®å½•: {speakers_dir}")
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            import time
            timestamp = int(time.time())
            file_extension = source_path.suffix
            filename = f"user_reference_{timestamp}{file_extension}"
            dest_path = speakers_dir / filename
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_path, dest_path)
            
            # éªŒè¯æ–‡ä»¶
            if dest_path.exists() and dest_path.stat().st_size > 0:
                file_size = dest_path.stat().st_size
                print(f"âœ… å‚è€ƒéŸ³é¢‘å¤åˆ¶æˆåŠŸ: {dest_path}")
                print(f"æ–‡ä»¶å¤§å°: {file_size/1024/1024:.2f}MB")
                return filename  # è¿”å›æ–‡ä»¶åï¼Œä¸æ˜¯å®Œæ•´è·¯å¾„
            else:
                print(f"âŒ å‚è€ƒéŸ³é¢‘å¤åˆ¶å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ å‡†å¤‡å‚è€ƒéŸ³é¢‘å¼‚å¸¸: {str(e)}")
            return None
    
    def get_available_voices(self) -> list:
        """è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.base_url}/voices", timeout=10)
            if response.status_code == 200:
                return response.json().get("voices", ["default"])
            return ["default"]
        except:
            return ["default"]
    
    def create_silence_audio(self, duration: float, output_filename: str) -> Optional[str]:
        """åˆ›å»ºé™éŸ³éŸ³é¢‘æ–‡ä»¶"""
        try:
            from pydub import AudioSegment
            
            # åˆ›å»ºæŒ‡å®šæ—¶é•¿çš„é™éŸ³
            silence = AudioSegment.silent(duration=int(duration * 1000))  # è½¬æ¢ä¸ºæ¯«ç§’
            
            output_path = Config.AUDIO_DIR / f"{output_filename}.wav"
            silence.export(output_path, format="wav")
            
            return str(output_path)
            
        except Exception as e:
            print(f"åˆ›å»ºé™éŸ³éŸ³é¢‘å¤±è´¥: {str(e)}")
            return None
    
    def _split_text_into_sentences(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å¥å­ï¼ˆä¸­è‹±æ–‡å…¼å®¹ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]+', text)
        # è¿‡æ»¤ç©ºå¥å­å¹¶ä¿ç•™æ ‡ç‚¹ç¬¦å·
        result = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence:
                result.append(sentence)
        return result
    
    def _calculate_sentence_durations(self, sentences: List[str], total_duration: float) -> List[float]:
        """æ ¹æ®å¥å­é•¿åº¦åˆ†é…æ—¶é•¿"""
        if not sentences:
            return []
        
        # è®¡ç®—æ¯ä¸ªå¥å­çš„å­—ç¬¦æ•°
        sentence_lengths = [len(sentence) for sentence in sentences]
        total_length = sum(sentence_lengths)
        
        if total_length == 0:
            # å¦‚æœæ€»é•¿åº¦ä¸º0ï¼Œå¹³å‡åˆ†é…æ—¶é•¿
            duration_per_sentence = total_duration / len(sentences)
            return [duration_per_sentence] * len(sentences)
        
        # æŒ‰ç…§å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é•¿
        durations = []
        for length in sentence_lengths:
            duration = (length / total_length) * total_duration
            # ç¡®ä¿æ¯ä¸ªå¥å­è‡³å°‘æœ‰1ç§’çš„æ˜¾ç¤ºæ—¶é—´
            duration = max(duration, 1.0)
            durations.append(duration)
        
        return durations
    
    def _seconds_to_srt_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def text_to_speech_with_subtitles(self, text: str, output_filename: str, 
                                     voice: str = "default", speed: float = 1.0) -> Dict[str, Optional[str]]:
        """ç”Ÿæˆè¯­éŸ³å’Œå­—å¹•æ–‡ä»¶"""
        result = {
            'audio_file': None,
            'subtitle_file': None
        }
        
        try:
            # æ¸…ç†æ–‡æœ¬ï¼Œè¿‡æ»¤æ‰æ‹¬å·å†…çš„éŸ³æ•ˆè¯´æ˜
            cleaned_text = self._clean_audio_script(text)
            
            # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶ï¼ˆä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬ï¼‰
            audio_file = self.text_to_speech(cleaned_text, output_filename, voice, speed)
            result['audio_file'] = audio_file
            
            if audio_file:
                # è·å–éŸ³é¢‘æ—¶é•¿
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_wav(audio_file)
                    duration = len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
                except ImportError:
                    # å¦‚æœæ²¡æœ‰pydubï¼Œä¼°ç®—æ—¶é•¿
                    word_count = len(cleaned_text.split())
                    duration = word_count / (2.5 * speed)  # æ ¹æ®è¯­é€Ÿè°ƒæ•´
                
                # ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬ï¼‰
                subtitle_file = self.generate_subtitles(cleaned_text, output_filename, duration)
                result['subtitle_file'] = subtitle_file
            
            return result
            
        except Exception as e:
            print(f"ç”Ÿæˆè¯­éŸ³å’Œå­—å¹•å¤±è´¥: {str(e)}")
            return result
